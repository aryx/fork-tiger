\documentclass[twocolumn]{report}

%******************************************************************************
% Prelude
%******************************************************************************
\newif\iffinal
\newif\ifverbose
\finaltrue\verbosefalse % see also other newif in Macros.tex

%------------------------------------------------------------------------------
%history: 
%------------------------------------------------------------------------------

%thx to LP, changed for the better a few things. 
% - introduce extra types ('name', 'typename') to avoid overload 'symbol'
%   so clearer types I think (symbol * symbol -> name * typename),
%   introduced also 'is_ptr' instead of bool,
% - removed Temp useless constructor (also less confusing with Tree.TEMP)
% - rename acc to access, acc has too much meaning usually for accumulator
% - removed ast_node type, pass env explicitly to trdec and trexp

%Actually I re-lpized this document so here is what I think is now better:
% - get first an overview of all the core DS
% - get first an overview of the main functions, the main concepts/types,
%   so you know where you go. Easier to orientate yourself I think.
% - LP split things (environment.t, Ast, vartype ...) so can expose
%   first a simpler version, for instance present SEQ and ESEQ later
% - AST is put closer to the grammar (update: actually was bad, but
%   at least I aspectized a few constructions like Spawn, exns)
% - I reordered AST elts, for instance CONST is before BINOP.
% - I put the entry points of modules first, so know the goal/context
%   so better understand the helpers presented later. Same for nested
%   helper functions that I present later. You don't have to follow
%   the order of the file imposed by the compiler.
% - I think he often just paraphrases the code. I'd rather comment
%   subtleties, history notes, design alternatives, bugfixes
% - TODO more examples of values, like in THIH

%thx to codemap/codegraph/scheck:
% - TODO use cg to reduce backward deps, introduce globals.c, utils.c,
%   (harder to understand non layered code)
% - TODO use scheck to remove deadcode, dead prototypes, useless export
%   or mv as forward decl
%   (harder to understand big interface files)
% - TODO use cg to reduce number of globals by moving them closer to the
%   relevant file (or even function), better cluster the code
%   (harder to understand non functional code using lots of globals)

%thx to this manual, better understand compilers and/or language design:
% - mutual recursivity handling (list of things together, as in ocaml)
%   alt: forward decl as in C
% - scope handling (global for types only, as in ocaml)
%   alt: mess as in C where structures can be nested which leads to
%   complex edge cases. KISS!
% - type names in the right part of types are actually essential, not
%   just for typedefs, but to handle mutually recursive or recursive
%   data structure!
% - the main essential compilation algorithms (labelization, frameization, 
%   offsetization, etc)

%history LP-ization:
% - skeleton, mostly copy paste of Template.nw skeleton
% - put all content of files in the Extra section, via 'pfff -lpize'
%   which also now split in chunks!
%    * function, global, struct, enum, constant, macro(actually function)
%    * TODO ctor/dtor, dumper
%    * TODO [[xxx]] other fields, [[xxx]] extra fields
% - read Extra section, identify concepts, first TOC
% - SEMI distribute parts of the Extra section in the main file
% - TODO understand main(), LP split main, improve TOC
% - TODO understand main functions, LP split, cluster, improve TOC
% - LP split the structures, use datalog for flow to field info
% - TODO nullify, boolify, errorify, enumify,  typeify,    scheckify, plan9ify
% - SEMI aspecify advanced features! remove useless features
% - TODO add figures
% - TODO add explanations

%------------------------------------------------------------------------------
% Packages
%------------------------------------------------------------------------------

\usepackage{docs/latex/noweb}
 \noweboptions{footnotesizecode,nomargintag}
 %note: allow chunk on different pages, less white space at bottom of pages
 \def\nwendcode{\endtrivlist \endgroup}
 \let\nwdocspar=\par
\usepackage{xspace}
\usepackage{verbatim}
%note: required by noweblatexpad for the \t \l \n in this file
\usepackage{fancyvrb}
\usepackage{url}
\iffinal
\usepackage{hyperref}
 \hypersetup{colorlinks=true}
\fi
\usepackage[pageref]{backref}
 \def\backref{{\footnotesize cited page(s)}~}
%\usepackage{cleveref} %\cref
%\usepackage{multirow}
\usepackage{booktabs} 
 \newcommand{\otoprule}{\midrule[\heavyrulewidth]}
\usepackage{graphicx}
 %\usepackage[margin=0.5in]{geometry}
 %  but eat the bottom when very low
 %\usepackage{fullpage} is deprecated 
 % => do the more manual below:
 \addtolength{\oddsidemargin}{-.850in}
 \addtolength{\evensidemargin}{-.850in}
 \addtolength{\textwidth}{1.70in}
 \addtolength{\topmargin}{-.850in}
 \addtolength{\textheight}{1.70in}
%\usepackage{minitoc}

%------------------------------------------------------------------------------
% Macros
%------------------------------------------------------------------------------
\input{docs/latex/Macros}

%------------------------------------------------------------------------------
% Config
%------------------------------------------------------------------------------
\allcodefalse
% used for ?

%\setcounter{tocdepth}{1}

%******************************************************************************
% Title
%******************************************************************************

\begin{document}

\title{
{\Huge 
Principia Softwarica: The Tiger Compiler Frontend [[tigerc]]
}\\
{version 0.1}
}

\author{
Yoann Padioleau\\
\texttt{yoann.padioleau@gmail.com}\\
\\
with code from\\
Paul Govereau
}
% And Andrew Appel?

\maketitle 
\onecolumn
\hrule
\begin{quote}
    Copyright \copyright{} 2015 Yoann Padioleau \\
    Permission is granted to copy, distribute and/or modify this document,
    except all the source code it contains, under the terms of the GNU Free
    Documentation License, Version 1.3.
\end{quote}
\hrule

%CONFIG: \dominitoc

\iffinal
\begingroup
\hypersetup{linkcolor=blue}
% need to s/onecolumn/twocolumn in report.cls :) for \tableofcontents
\twocolumn
\tableofcontents
\endgroup
\else
\tableofcontents
\fi

%******************************************************************************
% Body
%******************************************************************************

\chapter{Introduction}

\section{Motivations}

The goal of this book is to present in full details the source code of
a compiler.
% frontend
Why? Because I think it makes you a better programmer if
you fully understand how things work under the hood.

% choose tiger because very simple language but has lots of the
% essential features of a language like C or pascal and can showcase
% the essential compilation algorithms.

%% vs original tigerc.pdf manual? no file/module fixed boundaries, so
%% can LP-split and aspectize AST elements for instances.

%% Hmm not redundant with Compiler.nw and even now OCaml.nw? Maybe but
%% maybe it can help me to first have a cleaner and simpler compiler.
%% So maybe making this manual can improve later Compiler.nw and OCaml.nw.
%% Can also see a simpler GC, which again can improve later OCaml.nw.

Here are other candidates that were considered but ultimately discarded:
\begin{itemize}
\item gcc
\item clang
\end{itemize}

% other:
% - blue? also a toy language for learning

\section{Getting started}

\section{Requirements}

\section{About this document}
#include "docs/latex/About.nw"

\section{Copyright}

Most of this document is actually source code from Paul Govereau, so
those parts are copyright by him.
The prose is mine and is licensed under the GNU Free Documentation
License.

\section{Acknowledgments}


\chapter{Overview}

\section{Compiler principles}
% compiler frontend principles?

% to compile is to translate from language A to language B.
% In our case from Tiger (=~ C), to C-- (=~ Assembly).

% The main compilation algorithms in our care are:
%  - "labelization": structured nested statements (including functions) to 
%     basic flat goto/labels 
%  - "linearization": complex "recursive" expressions to 
%     basic flat instructions and the introduction of temporary variables
%  - "frameization": structured entities with params, arguments, locals, to
%     basic stack operations
%  - "offsetization": structured access in records and array to
%     basic memory offsets (a form of pointer arithmetic)
%  - "layouting": structured data section and complex data initialization to
%     basic bytes layout

% Then in addition to that there is the lexing/parsing and typechecking.

\section{[[tigerc]] services}

<<function Option.usage>>=
let rec usage() = 
  Arg.usage options "Usage:";
  exit 0;
@
% tigerc [options] <inputfile> > <c--file> where options are:
% or even tigerc < inputfile > outputfile

\section{[[helloworld.tig]]}

% demos/hello.tig

<<demos/hello.tig>>=
/* hello world */ 
let
  var a := "Hello, world.\n"
in 
  print(a)
end
@

% not so different from Asm, but still print(a) is better
% than an unchecked PUSH A; CALL print.

\section{Input Tiger language}

% toy language.
%  - no declarations (no header file), a single file with possibly mutually
%    recursive functions
%  - no modules (no qualifier), so name resolution simple (even though
%    scoped/nested language), and no linking really. Compile a single file.
%  - no pointers
%  - no union
%  - no general polymorphic types (ANY??), have just polymorphic arrays
%  - no float
%  - no switch
%  - no goto/labels (but generate code using goto/labels), goto considered
%    harmful spirit I guess

% but has a few nice things:
%  - limited form of type inference :) no need to declare type of VarDec
%    'var' keyword a la C++ auto
%  - nested functions (but no closure, can't return or have variable
%    holding functions)
%  - statements are expressions. If is an expression :) no need ? : ugly 
%    syntax.

\section{Output C-- language}

% =~ Assembly

\section{Code organization}

\section{Software architecture}

% classic compiler archi:
% lexer -> parser -> typechecker & IR-generator -> linearizer -> c-- generator 
% and on the side have runtime and stdlib "linked" with the generated file.

%###############################################################################

\chapter{Core Data Structures}

\section{Abstract syntax tree}

%note: actually I put the main constructors below. I did that in Ocaml.nw
% and it's better I think. AST is a really core DS, we can't wait to
% see the grammar to get an idea of what is the language. Anyway if we
% do not put the main cases here, it's
% weird after in Type section to have RECORD, ARRAY, etc because
% we have no idea where they come from. Same for IR tree.

\subsection{Positions}

<<type Ast.pos>>=
type pos = int 
@
% for error reporting, int = charpos, see Error appendix

% below he has added pos as an extra tuple element.
%alt: the 'a wrap tech in pfff, the record_expr in OCaml.nw, the
% extra constructor ExpPos, etc.

% then there is an extra mapping table for the charpos -> line
%alt: have all info in the wrap in pfff, the linenum.mll in OCaml.nw, etc.

\subsection{Names}

<<type Ast.name>>=
type name = Symbol.symbol
@
% see below, =~ string
%old: was type symbol = Symbol.symbol but better rename name (or ident)

<<type Ast.typename>>=
type typename = Symbol.symbol
@

% same namespace? hmm have tenv and venv later so different namespace
% and no parsing ambiguity because have 'var' or 'type' before.

\subsection{Definitions}
% Was Declarations but it's actually more definitions

% defs
<<type Ast.dec>>=
type dec =
| VarDec       of name * typename option * exp * pos
| TypeDec      of (typename * ty * pos) list
| FunctionDec  of (name * field list * typename option * exp * pos) list
<<[[Ast.dec]] cases>>
@
% list for TypeDec and FunctionDec so can have mutually recursive things
% typename option for VarDec so have a form of type inference!

% note that use typename so it forces to introduce a name for everything,
% can't do var a : array int; have to introduce intermediate name.

<<type Ast.field>>=
and field = (name * typename * pos)
@

%ex? dump? actually have a -dump_ast!

\subsection{Expressions}

% uses
<<type Ast.exp>>=
and exp =
| NilExp
| IntExp    of int
| StringExp of string * pos

| VarExp    of var

| OpExp     of exp * oper * exp * pos
| CallExp   of name * exp list * pos

| RecordExp of name * (name * exp * pos) list * pos
| ArrayExp  of name * exp * exp * pos

| LetExp    of dec list * exp * pos

<<[[Ast.exp]] statement cases>>
<<[[Ast.exp]] cases>>
@
% also include stmt, expression language!
%ex?

% Nil?
% CallExp of name, so no complex function call.
% note that VarExp contains the field and array elt access.
% RecordExp and ArrayExp are "constructors" not accessors.

% =~ rvalue and lvalue
<<type Ast.var>>=
and var =
    SimpleVar    of name * pos
  | FieldVar     of var * name * pos
  | SubscriptVar of var * exp * pos
@
% recursif! so can do x.f.y.w (which is ((x.f).y).w
% no pointer here


%Ast.oper here?

\subsection{Statements}

<<[[Ast.exp]] statement cases>>=
| AssignExp of var * exp * pos
| SeqExp    of exp list * pos
| IfExp     of exp * exp * exp option * pos
| WhileExp  of exp * exp * pos
| ForExp    of name * exp * exp * exp * pos
| BreakExp  of pos
@
% actually ForExp is sugar for While, so could aspectize. Could also
% aspectize BreakExp.
% note that no goto/labels here.
% we will see exceptions later.
% If are actually expressions in Tiger.

\subsection{Types}

<<type Ast.ty>>=
and ty =
| NameTy   of typename * pos
| RecordTy of field list
| ArrayTy  of typename * pos
@
% namety can be also for builtin types!
% no size in ArrayTy, lose information when type
% not a recursive type because force to name every intermediate
% just array are polymorphics (like in C)

%ex?

%less: Need Array? can be seen as some form of sugar?

\section{Type system}
% and the environment?

<<type Environment.vartype>>=
type vartype =
  (* basic types *)
  | UNIT
  | INT
  | STRING

  (* aggregate types *)
  | RECORD of (Ast.name * vartype) list
  | ARRAY  of vartype

  (* other types *)
  <<[[Environment.vartype]] cases>>
@ 
% this one is recursive! expanded the intermediate names

<<[[Environment.vartype]] cases>>=
| NIL
@
% NIL = Null = unitialized record

<<[[Environment.vartype]] cases>>=
| ANY
@
% ANY? for unknown array?

\section{Symbol table}
% Scope system

% for use/def checking, lookup attributes, etc. classic.

\subsection{Unique symbols}

<<type Symbol.symbol>>=
type symbol = string * int
@
% will be used for many things, for many "namespaces"
%  - name (var ident, func ident)
%  - field ident, 
%  - exn ident
%  - typename
%  - label in intermediate code
%  - temps in intermediate code
%  - frame pointer

% int? a stamp to make sure things are unique?
%todo: but need that??

%note: no qualifier, no module system, no linking modules.


% used for gensym like functionality too
<<global Symbol.nextsym>>=
let nextsym = ref 0
@

<<global Symbol.hashtable>>=
let (hashtable: (string, int) Hashtbl.t) = Hashtbl.create 128
@
% get the current stamp given a symbol name
%todo: need that again??

<<function Symbol.name>>=
let name = fst
@
<<function Symbol.uid>>=
let uid  = snd
@
%uid = unique id (not user id)

% both a constructor and accessor
<<function Symbol.symbol>>=
let symbol name =
  try 
    let uid = Hashtbl.find hashtable name in 
    (name,uid)
  with Not_found ->
    incr nextsym; 
    Hashtbl.add hashtable name !nextsym;
    (name, !nextsym)
@
%todo: how this function is used? a bit weird to imagine
% really need this uid?

\subsection{Symbol table}

<<type Symbol.table>>=
type 'a table = {
    tbl    : (symbol, 'a) Hashtbl.t;
    <<[[Symbol.table]] other fields>>
  }
@
% usually Ast.ty table; or Ast.ty Env.enventry table.


<<function Symbol.enter>>=
let enter env sym v =
  if Hashtbl.mem env.tbl sym
  then failwith "Compiler error: symbol table duplicate entry"
  else Hashtbl.add env.tbl sym v
@

<<function Symbol.mem>>=
let mem env sym = 
  Hashtbl.mem env.tbl sym
@


<<constructor Symbol.create>>=
let create l =
  let env = {
    tbl = Hashtbl.create 20;
    level = 0;
    parent = None
  } in
  l |> List.iter (fun (key, data) -> enter env (symbol key) data);
  env
@
%less: rename create_table?

\subsection{Scope managment}

<<[[Symbol.table]] other fields>>=
parent : 'a table option;
@


% different from mem() we've seen above, here we recurse
<<function Symbol.look>>=
let rec look env sym =
  try Hashtbl.find env.tbl sym
  with Not_found -> 
    (match env.parent with
    | None -> raise Not_found
    | Some e -> look e sym
    )
@


<<constructor Symbol.new_scope>>=
let new_scope env = { 
  tbl = Hashtbl.create 20;
  level = env.level + 1;
  parent = Some env 
}
@


<<[[Symbol.table]] other fields>>=
level  : int;
@
% level is for? for stack frames because have nested func
% we sometimes need to access data in previous frames so we need
% to maintain in which level we currently are (and store in which
% level the variable we want to access lives)

%\section{Environment}
% see later, but more local to one phase, so less need to expose it here

\section{Intermediate code}
% linearized tree
% (presented in core DS because it's useful to know where we go)

\subsection{Instructions and labels}
% labelization

<<type Tree.stm>>=
type stm =
  | EXP    of exp
  | MOVE   of exp * exp

  | LABEL  of label
  | JUMP   of exp
  | CJUMP  of exp * label * label
  | RET    of exp
  <<[[Tree.stm]] cases>>
@
%less: rename to instr instead?
%nites:
% CJUMP = conditional jmp
% JUMP will be at the end of only a label or a const no?
% MOVE is src dst (src -> dst)
%compile: diff with before? have labels and jumps! so closer
% to assembly. No more if, while, for.
% also introduce a real stm type! start split for real expr and stmt.


% In the end we will generate for a function a list of stm.
% See linearize type.

%less: What EXP is for? dead code? for function call that don't return
% anything? could remove?

<<type Tree.label>>=
type label = Symbol.symbol
@
% labelization

\subsection{Basic expressions and temporaries}
% linearization, offsetization
% intermediate temporaries for complex expressions

<<type Tree.exp>>=
and exp =
  | CONST of int
  | BINOP of binop * exp * exp
  | RELOP of relop * exp * exp

  | NAME  of label
  | TEMP  of temp * is_ptr
  | MEM   of exp * is_ptr (* dereference? *x ? *)

  | CALL  of exp * exp list * string option * label option * is_ptr
  <<[[Tree.exp]] cases>>
@
%compile: diff with before? Not much yet.
% hmm not really linearized. 
% linearize() actually (ab)use the same structure but with
% extra postconditions on the form of the tree.

% so foo(1,2) will be translated in 
% CALL (NAME "foo", [CONST 1; CONST 2]).

<<type Tree.temp>>=
and  temp  = Symbol.symbol
@
% when we will lineraize then binop will have only "basic" children
% in which case intermediate values will be stored in those 'temp'
% variables. so x = 1+2+3; become temp1 = 2+3; temp2 = 1+temp1; x = temp2

<<types Tree.xxxop>>=
and binop = PLUS | MINUS | MUL | DIV
and relop = EQ | NE   | LT | GT | LE | GE
@

%ex:


<<[[Tree.stm]] cases>>=
| SEQ    of stm * stm
@
% this will disappear after linearization

<<[[Tree.exp]] cases>>=
| ESEQ  of stm * exp
@
% Ugly to have ESEQ here, can have many different forms, EXP ESEQ SEQ ESEQ ...
% But Expression sequence is convenient because we want many of our
% function to return an expression. But this will be linearized
% also and removed.

% actually after linearize have this invariant:
%%The tree contains no [[SEQ]] or [[ESEQ]] nodes.
% which is why linearize return a stm list;
%%The parent of every [[CALL]] node is either an [[EXP]] or a
%%[[MOVE(...,TEMP _)]].

\subsection{Pointers}

<<type Tree.is_ptr>>=
type is_ptr = bool
@
% important in compilation context, will see later, no need to track
% full type of data but important dichotomy to track is whether
% pointer or word.
%todo: why?

<<function Semantics.is_ptr>>=
let is_ptr = function
    INT | UNIT -> false
  | NIL | RECORD _ | STRING | ARRAY _ -> true
  | _ -> E.internal "non-base type for variable"
@
% Need to carry this information a lot. Need to tag memory, params
% locals, temps, with it.
% Why ?? codegen differences?





\subsection{Stack frames}
% frameization

% locals, params, temporaries, all things not handled by
% exp above.

<<type Frame.frame>>=
type frame = { 
  mutable params : (Tree.label * Tree.is_ptr) list;
  mutable vars   : (Tree.label * Tree.is_ptr) list;
  mutable temps  : (Tree.label * Tree.is_ptr) list;
  <<[[Frame.frame]] other fields>>
}
@
% the 3 essential things in a stack! params, locals, temps
% note that mutable!

% A function is really a linearized body and frame information.
% The frame is like the "head" of the function, and the exp its body
% (which after linearize is transformed in a list of stm/instructions) 

%XXX
<<[[Frame.frame]] other fields>>=
name           : Tree.label;
@
<<[[Frame.frame]] other fields>>=
level          : int;
@




\chapter{[[main()]]}

<<function Main.main>>=
let main () =
  try
    Option.parse_cmdline();
    compile !Option.inch
  with Error.Error ex ->
    Error.handle_exception ex
@
% see handle_exception in Error appendix

<<toplevel Main._>>=
let _ = 
  main ()
@

<<signature global Option.inch>>=
val inch      : in_channel ref
@
<<command line flags>>=
let inch   = ref stdin
@

\section{Command line processing}

<<signature function Option.parse_cmdline>>=
val parse_cmdline : unit -> unit
@
% main -> <>
<<function Option.parse_cmdline>>=
let parse_cmdline() = 
  Arg.parse options set_input "Usage:"
@


<<constant Option.options>>=
and options = [
  <<command line options>>
  "-help",     Arg.Unit usage, "\tprint this message";
]
@
% will see more command line options later

<<command line flags>>=
let file   = ref ""
@

% main -> parse_cmdline -> Arg.parse -> set_input (as x <- parse_cmdline)
<<function Option.set_input>>=
let set_input s =
  try 
    file := s; 
    inch := open_in s
  with Sys_error err ->
    raise (Arg.Bad ("could not open file " ^ err))
@



\section{[[Main.compile()]]}

<<function Main.compile>>=
let compile ch =
  (* parsing *)
  let lexbuf = Lexing.from_channel ch in
  let ast = Parser.program Lexer.token lexbuf in
  <<[[Main.compile()]] if dump AST option>>

  (* checking and compiling part1 *)
  let base_env = Environment.new_env base_tenv base_venv in
  let xs = Semantics.translate base_env ast in

  <<[[Main.compile()]] generate headers>>
  <<[[Main.compile()]] generate data before functions>>

  (* compiling part2 and generating *)
  xs |> List.iter emit_function 
@

<<signature function Lexer.token>>=
val token : Lexing.lexbuf -> Parser.token
@
% get a list of functions. for toplevel expressions there is an
% implicit tiger_main enclosing function.

%signature Parser.program is actually in generated file parser.mli
% so orphaned chunk below
<<signature function Parser.program>>=
val program :
  (Lexing.lexbuf  -> token) -> Lexing.lexbuf -> Ast.exp
@


<<signature function Environment.new_env>>=
val new_env : (string * vartype) list ->
              (string * string option * vartype list * vartype) list -> t
@
% type defs, function defs (string option?)

<<signature function Semantics.translate>>=
val translate : Environment.t -> Ast.exp -> (Frame.frame * Tree.exp) list
@
% one for each function. A function is really a set of statements (the body)
% and some frame information for the params, locals, temps.

\section{[[Main.emit_function()]]}


<<function Main.emit_function>>=
let emit_function (frm, ex) =
  (* compiling *)
  <<[[Main.emit_function()]] if dump expression tree>>
  let ltree = Canonical.linearize (Tree.EXP ex) in
  <<[[Main.emit_function()]] if dump linearized tree>>
  <<[[Main.emit_function()]] adjust frm with temporaries in ltree>>

  (* generating *)
  Frame.output_header frm;
  Codegen.emit ltree;
  Frame.output_footer frm
@

<<signature function Canonical.linearize>>=
val linearize : Tree.stm -> Tree.stm list
@
% but should use another DS where can more clearly see the restrictions
% on the shape of the tree


<<signature function Frame.output_header>>=
val output_header  : frame -> unit
@
<<signature function Frame.output_footer>>=
val output_footer  : frame -> unit
@

<<signature Codegen.emit>>=
val emit               : Tree.stm list -> unit
@



\chapter{Lexing}

% Lexer.token()

\section{Overview}

<<lexer.mll>>=
{
module E = Error
module P = Parser

<<global Lexer.keyword_table>>
<<function Lexer.escape>>
<<Lexer globals>>
}

<<Lexer aliases>>

<<rule token>>
<<rule comment>>
<<rule string>>
@


<<rule token>>=
rule token = parse
  <<[[Lexer.token]] cases>>
  | eof  { P.EOF }
  | _
      { raise (E.Error(E.Illegal_character (Lexing.lexeme_char lexbuf 0),
                       Lexing.lexeme_start lexbuf)) }
@


%\section{Token}
% can see different concepts already
% in parser.mly but really related to lexing
<<token declarations>>=
%token <string> ID
%token <int> INT
%token <string> STRING
%token IF THEN ELSE END  WHILE DO FOR TO BREAK
%token PLUS MINUS TIMES DIVIDE
%token AND OR
%token EQ NEQ  LT LE GT GE
%token FUNCTION VAR LET IN
%token TYPE OF ARRAY
%token ASSIGN COLON COMMA DOT SEMICOLON 
%token LPAREN RPAREN  LBRACE RBRACE  LBRACK RBRACK
%token NIL
%token EOF
@


% no position information here, no use of Lexing.lexeme_char()
% but instead use Parsing.symbol_start()


\section{Spaces and newlines}

<<Lexer aliases>>=
let nl = ['\010' '\013']
let blank = [' ' '\009' '\012']
@
% C-j, C-m
% Tab (C-i), C-l (PageDown)

<<Lexer globals>>=
let line_num = ref 0
@

<<[[Lexer.token]] cases>>=
|  nl   { incr line_num;
         E.add_source_mapping (Lexing.lexeme_end lexbuf) !line_num;
         token lexbuf }
| blank + { token lexbuf }
@
%E = Error
% important for error reporting, see appendix

\section{Comments}

<<[[Lexer.token]] cases>>=
| "/*" { comment lexbuf; token lexbuf }
@
% call back original rule

<<Lexer globals>>=
let comment_pos = Stack.create()
@

% nested comment handling, but not single line comment :(
<<rule comment>>=
and comment = parse
    "/*" { Stack.push (Lexing.lexeme_start lexbuf) comment_pos;
           comment lexbuf; }
  | "*/" { try (ignore(Stack.pop comment_pos); comment lexbuf)
           with Stack.Empty -> () }
  | nl   { incr line_num;
           E.add_source_mapping (Lexing.lexeme_end lexbuf) !line_num;
           comment lexbuf }
  | eof  { let st = Stack.top comment_pos in
           raise (E.Error(E.Unterminated_comment, st)) }
  | _    { comment lexbuf }
@

\section{Identifiers and keywords}

<<Lexer aliases>>=
let letter = ['A'-'Z' 'a'-'z']
let identchar = ['A'-'Z' 'a'-'z' '_' '0'-'9']
@

<<[[Lexer.token]] cases>>=
| letter identchar *
    { let s = Lexing.lexeme lexbuf in
      try
        Hashtbl.find keyword_table s
      with Not_found ->
        P.ID s 
    }
@


<<global Lexer.keyword_table>>=
(* The table of keywords *)
let keyword_table = Hashtbl.create 22;;
List.iter (fun (key, data) -> Hashtbl.add keyword_table key data)
  [
   "if",        P.IF;
   "then",      P.THEN;
   "else",      P.ELSE;
   "while",     P.WHILE;
   "do",        P.DO;
   "for",       P.FOR;
   "to",        P.TO;
   "end",       P.END;
   "break",     P.BREAK;

   "function",  P.FUNCTION;
   "var",       P.VAR;
   "let",       P.LET;
   "in",        P.IN;

   "type",      P.TYPE;
   "of",        P.OF;
   "array",     P.ARRAY;

   "and",       P.AND;
   "or",        P.OR;

   "nil",       P.NIL;

   <<[[Lexer.keyword_table]] entries>>
 ]
@
% no pointers, no class, no ADTs, very basic indeed.

\section{Operators}

<<[[Lexer.token]] cases>>=
| "+"  { P.PLUS }
| "-"  { P.MINUS }
| "*"  { P.TIMES }
| "/"  { P.DIVIDE }

| "&"  { P.AND }
| "|"  { P.OR }

| "="  { P.EQ }
| "<>" { P.NEQ }

| ">"  { P.GT }
| "<"  { P.LT }
| ">=" { P.GE }
| "<=" { P.LE }
@



\section{Punctuations}

<<[[Lexer.token]] cases>>=
| ":=" { P.ASSIGN }
| ":"  { P.COLON }
| ","  { P.COMMA }
| "."  { P.DOT }
| ";"  { P.SEMICOLON }

| "{"  { P.LBRACE } | "}"  { P.RBRACE }
| "["  { P.LBRACK } | "]"  { P.RBRACK }
| "("  { P.LPAREN } | ")"  { P.RPAREN }
@

\section{Numbers}

<<Lexer aliases>>=
let number = ['0'-'9']
@

<<[[Lexer.token]] cases>>=
| number +
    { P.INT (int_of_string(Lexing.lexeme lexbuf)) }
@

% no float ?


\section{Strings}

% no chars? no unicode?

<<[[Lexer.token]] cases>>=
| "\"" 
    { string_start_pos := Lexing.lexeme_start lexbuf;
      Buffer.clear buffer;
      P.STRING (string lexbuf) }
@

<<Lexer globals>>=
let string_start_pos = ref 0
let buffer = Buffer.create 30
@


<<rule string>>=
and string = parse
    '"'
      { Buffer.contents buffer }
  | '\\' ['\\' '\'' '"' 'n' 't' 'b' 'r']
      { Buffer.add_char buffer (escape (Lexing.lexeme_char lexbuf 1));
        string lexbuf }
  | [^ '"' '\\'] +
      { Buffer.add_string buffer (Lexing.lexeme lexbuf);
        string lexbuf }
  | eof
      { raise (E.Error(E.Unterminated_string, !string_start_pos)) }
@
%old:      { let s = Buffer.contents buffer in
%        (Buffer.clear buffer; s) }

<<function Lexer.escape>>=
(* To buffer string literals *)
let escape c = 
  match c with
  | 'n' -> '\n'
  | 'r' -> '\r'
  | 'b' -> '\b'
  | 't' -> '\t'
  | _ -> c
@







\chapter{Parsing}

% Parser.program()

\section{Overview}

<<parser.mly>>=
%{
module E = Error
module A = Ast
module S = Symbol

<<parser helper functions>>
<<AST mk wrappers>>
%}

/* Tokens */
<<token declarations>>

/* Precedences and associativities (from low to high) */
<<token priorities>>

/* start symbols */
%start program
<<rule type declarations>>

/* %expect 63 */

%%
<<grammar>>
@ 
% 63 conflicts??? actually gets 66.
%todo: remove all those conflicts, no reason.


<<grammar>>=
<<rule program>>

/* Expressions */
<<rule expr>>
<<rule lvalue>>
<<subrules for expr>>
<<subrules for stmt>>

/* Declarations */
<<rule decs>>
<<subrules for decs>>

/* Types */
<<rule ty>>

/* Names */
<<rule id>>
@







<<rule type declarations>>=
%type <Ast.exp> program
%type <Ast.exp> expr
%type <Ast.var> lvalue
%type <Ast.dec list> decs
@
% Parser.program, it's here!



<<rule program>>=
program:
  expr EOF { $1 }
@
%$

<<rule expr>>=
expr:
  LET decs IN expr_list END { mkLetExp $2 (mkSeqExp $4) }
@






\section{Definitions}
% actually it's declaration and definitions

% alt: have (forward) decl and def

<<rule decs>>=
/* recursive declarations in tiger.
   My interpretation of the tiger language spec is that
   mutally recursive types and functions are valid if they
   are declared together in a sequence. That is:
   type a = {b:int c:d} type d = a
   is valid where as 
   type a = {b:int c:d} var x := 1 type d = a
   is not.
*/
decs:
   dec { $1 :: [] }
 | dec decs { $1 :: $2 }
@
%$

<<subrules for decs>>=
<<rule dec>>
<<rule var_dec>>
<<rule type_decs>>
<<rule fun_decs>>
<<rule exn_dec>>
@

<<rule dec>>=
dec:
   var_dec   { $1 }
 | type_decs { mkTypeDec $1 }
 | fun_decs  { mkFunctionDec $1 }
 | exn_dec   { $1 }
@



\subsection{Variables}

%<<[[Ast.dec]] cases>>=
%| VarDec       of symbol * symbol option * exp * pos
%@

<<rule var_dec>>=
var_dec:
   VAR id ASSIGN expr          { mkVarDec $2 None $4 }
 | VAR id COLON id ASSIGN expr { mkVarDec $2 (Some $4) $6 }
@
%$

<<rule id>>=
/* Symbols are created in this rule only */
id: ID { S.symbol $1 };
@
%$

\subsection{Types}

%<<[[Ast.dec]] cases>>=
%| TypeDec      of (symbol * ty * pos) list
%@
% list so can have mutually recursive things

<<rule type_decs>>=
type_decs:
   type_dec           { $1 :: [] }
 | type_dec type_decs { $1 :: $2 }
;
type_dec:
   TYPE id EQ ty { mkTyDec $2 $4 }
;
@
%$


\subsection{Functions}

%<<[[Ast.dec]] cases>>=
%| FunctionDec  of (symbol * field list * symbol option * exp * pos) list
%@
% list again for mutually recursive possibilities
% symbol option cos can be a procedure that returns nothing

<<rule fun_decs>>=
fun_decs:
   fun_dec          { $1 :: [] }
 | fun_dec fun_decs { $1 :: $2 }

fun_dec:
   FUNCTION id LPAREN ty_fields RPAREN EQ expr
     { mkFunDec $2 $4 None $7 }
 | FUNCTION id LPAREN ty_fields RPAREN COLON id EQ expr
     { mkFunDec $2 $4 (Some $7) $9 }
@

%todo: 1 s/r on FUNCTION, but why? rewrite as fun_decs fun_dec ?


\section{Expressions}

<<rule expr>>=
 | literal                   { $1 }
 | lvalue                    { mkVarExp $1 }
 | function_call             { $1 }
 | arithmetic                { $1 }
 | comparison                { $1 }
 | boolean                   { $1 }
 | construction              { $1 }
@
%$
% actually here the lvalue is really an rvalue

% no pointer!

\subsection{Literals}

%<<[[Ast.exp]] cases>>=
%| NilExp
%| IntExp    of int
%| StringExp of string * pos
%@

<<subrules for expr>>=
/* Literals */
literal:
   NIL    { A.NilExp }
 | INT    { mkIntExp $1 }
 | STRING { mkStringExp $1 }
@

% no float


\subsection{Variable, array and field accesses}
% rvalue

%<<[[Ast.exp]] cases>>=
%| VarExp    of var
%@

<<rule lvalue>>=
/* Variables (L-values) 
   This rule is overly explicit to avoid conflicts with 
   the construction rule below */
lvalue:
 | id                        { mkSimpleVar $1 }
 | id LBRACK expr RBRACK     { mkSubscriptVar (mkSimpleVar $1) $3 }

 | lvalue DOT id             { mkFieldVar $1 $3 }
 | lvalue LBRACK expr RBRACK { mkSubscriptVar $1 $3 }
@
%$
%old: id DOT id { ...} was useless and actually causing an
% additional s/r conflict
%todo:
% but the one with LBRACK needs to remain I think. Without it
% given 'id' and seing 'LBRACK' the parser could either reduce 'id' to 
% 'lvalue', or shift in the rule about ArrayExp
% it's because of ambiguity with constructor of arrays and records?

\subsection{Arithmetic}

<<token priorities>>=
%nonassoc ASSIGN
%left AND OR
%nonassoc EQ NEQ GT LT GE LE
%left PLUS MINUS
%left TIMES DIVIDE
%nonassoc UMINUS
@


%<<[[Ast.exp]] cases>>=
%| OpExp     of exp * oper * exp * pos
%@

<<type Ast.oper>>=
and oper =
<<[[Ast.oper]] cases>>
@

<<[[Ast.oper]] cases>>=
| PlusOp | MinusOp | TimesOp | DivideOp
@

<<subrules for expr>>=
/* Simple Arithmetic */
arithmetic:
   MINUS expr %prec UMINUS { mkOpExp (mkIntExp 0) $2 A.MinusOp }
 | expr PLUS expr          { mkOpExp $1 $3 A.PlusOp    }
 | expr MINUS expr         { mkOpExp $1 $3 A.MinusOp  }
 | expr TIMES expr         { mkOpExp $1 $3 A.TimesOp  }
 | expr DIVIDE expr        { mkOpExp $1 $3 A.DivideOp }
@

\subsection{Comparison}

<<[[Ast.oper]] cases>>=
| EqOp | NeqOp   
| LtOp | LeOp | GtOp | GeOp
@

<<subrules for expr>>=
/* Comparison */
comparison:
   expr EQ expr  { mkOpExp $1 $3 A.EqOp  }
 | expr NEQ expr { mkOpExp $1 $3 A.NeqOp }
 | expr GT expr  { mkOpExp $1 $3 A.GtOp  }
 | expr LT expr  { mkOpExp $1 $3 A.LtOp  }
 | expr GE expr  { mkOpExp $1 $3 A.GeOp  }
 | expr LE expr  { mkOpExp $1 $3 A.LeOp  }
@

\subsection{Boolean}

<<subrules for expr>>=
/* Boolean operators */
boolean:
   expr AND expr { mkIfExp $1 $3 (Some(mkIntExp 0)) }
 | expr OR expr  { mkIfExp $1 (mkIntExp 1) (Some $3) }
@

% ! short circuiting operators actually!
% abuse int for booleans :( ugly

\subsection{Function calls}

%<<[[Ast.exp]] cases>>=
%| CallExp   of symbol * exp list * pos
%@
% no dynamic funcall! fixed symbol

<<subrules for expr>>=
/* function call */
function_call:
   id LPAREN fun_args RPAREN { mkCallExp $1 $3 }

fun_args:
   /* empty */         { [] }
 | expr                { $1 :: [] }
 | expr COMMA fun_args { $1 :: $3 }
@
%$


\subsection{Constructions}

%<<[[Ast.exp]] cases>>=
%| RecordExp of symbol * (symbol * exp * pos) list * pos
%| ArrayExp  of symbol * exp * exp * pos
%@
% why symbol? for type name? =~ new? bot for arrays?

<<subrules for expr>>=
/* Record and array construction */
construction:
   id LBRACE ctor_list RBRACE    { mkRecExp $1 $3 }
 | id LBRACK expr RBRACK OF expr { mkArrayExp $1 $3 $6 }

ctor_list:
   id EQ expr                 { (mkRecFld $1 $3) :: [] }
 | id EQ expr COMMA ctor_list { (mkRecFld $1 $3) :: $5 }
@

% ambiguity here I think for LBRACK with lvalue

% what does 'x[1] of y' means??

\subsection{Local entity definitions}

%expr:
%  LET decs IN expr_list END { mkLetExp $2 (mkSeqExp $4) }
% saw Let in in overview section

%<<[[Ast.exp]] cases>>=
%| LetExp    of dec list * exp * pos
%@

\section{Statements}

<<rule expr>>=
 | sequence                  { mkSeqExp $1 }
 | if_statement              { $1 }
 | loop_statement            { $1 }
@
%$


\subsection{Sequence}

%<<[[Ast.exp]] cases>>=
%| SeqExp    of exp list * pos
%@

<<subrules for stmt>>=
/* Sequence expression */
sequence:
   LPAREN RPAREN           { [] }
 | LPAREN expr_list RPAREN { $2 }
@
%$
% paren, meh, as in ocaml, but unusual; should have used LBRACE I think

<<subrules for stmt>>=
expr_list:
   expr                     { $1 :: [] }
 | expr SEMICOLON expr_list { $1 :: $3 }
@
%$

% classic PL syntax choice, terminator vs separator. but not very
% important
%alt: as terminator (C), as optional terminator (ocaml)

\subsection{Assignments}

%<<[[Ast.exp]] cases>>=
%| AssignExp of var * exp * pos
%@

<<rule expr>>=
 | lvalue ASSIGN expr        { mkAssignExp $1 $3 }
@

\subsection{Conditionals}

%<<[[Ast.exp]] cases>>=
%| IfExp     of exp * exp * exp option * pos
%@

<<subrules for stmt>>=
/* If statements */
if_statement:
   IF expr THEN expr           { mkIfExp $2 $4 None }
 | IF expr THEN expr ELSE expr { mkIfExp $2 $4 (Some $6) }
@
%$

\subsection{Loops}

%<<[[Ast.exp]] cases>>=
%| WhileExp  of exp * exp * pos
%| ForExp    of symbol * exp * exp * exp * pos
%
%| BreakExp  of pos
%@
% no continue?

<<subrules for stmt>>=
/* Loop statements */
loop_statement:
   WHILE expr DO expr                 { mkWhileExp $2 $4 }
 | FOR id ASSIGN expr TO expr DO expr { mkForExp $2 $4 $6 $8 }
 | BREAK                              { mkBreakExp }
@
%$
% no downto.




\section{Types}

%<<[[Ast.ty]] cases>>=
%| NameTy   of symbol * pos
%| RecordTy of field list
%| ArrayTy  of symbol * pos
%@
% namety can be also builtin types!
% no size in ArrayTy, lose information when type


<<rule ty>>=
ty:
   id                      { mkNameTy $1 }
 | LBRACE ty_fields RBRACE { mkRecordTy $2 }
 | ARRAY OF id             { mkArrayTy $3 }

ty_fields:
   /* empty */                 { [] }
 | id COLON id                 { (mkField $1 $3) :: [] }
 | id COLON id COMMA ty_fields { (mkField $1 $3) :: $5 }
@
%$

\ifallcode
\section{Helpers}

<<parser helper functions>>=
let getpos = Parsing.symbol_start
@
% subtle! he does not use the lexer for position tracking (well he used
% it only for the pos -> line tracking) but the lr engine.

%less: could delete, inline
<<AST mk wrappers>>=
let mkField n t           = (n, t, getpos())

let mkSimpleVar v         = A.SimpleVar(v, getpos())
let mkFieldVar v t        = A.FieldVar(v, t, getpos())
let mkSubscriptVar v e    = A.SubscriptVar(v, e, getpos())

let mkVarExp v            = A.VarExp(v)
let mkIntExp i            = A.IntExp(i)
let mkStringExp s         = A.StringExp(s, getpos())
let mkCallExp f a         = A.CallExp(f, a, getpos())
let mkOpExp l r op        = A.OpExp(l, op, r, getpos())
let mkRecFld n e          = (n, e, getpos())
let mkRecExp n f          = A.RecordExp(n, f, getpos())
let mkSeqExp el           = A.SeqExp(el, getpos())
let mkAssignExp v e       = A.AssignExp(v, e, getpos())
let mkIfExp tst t e       = A.IfExp(tst, t, e, getpos())
let mkWhileExp tst b      = A.WhileExp(tst, b, getpos())
let mkForExp v lo hi body = A.ForExp(v, lo, hi, body, getpos())
let mkBreakExp            = A.BreakExp(getpos())
let mkLetExp decs body    = A.LetExp(decs, body, getpos())
let mkArrayExp v s init   = A.ArrayExp(v, s, init, getpos())

let mkHandler name exp    = (name, exp, getpos())
let mkTryExp exp handlers = A.TryExp(exp, handlers, getpos())
let mkRaise id            = A.RaiseExp(id, getpos())

let mkSpawn id            = A.SpawnExp(id, getpos())

let mkFunDec n f t b      = (n, f, t, b, getpos())
let mkFunctionDec l       = A.FunctionDec(l)
let mkVarDec n t i        = A.VarDec(n, t, i, getpos())
let mkTyDec n t           = (n, t, getpos())
let mkTypeDec l           = A.TypeDec(l)
let mkNameTy n            = A.NameTy(n, getpos())
let mkRecordTy l          = A.RecordTy(l)
let mkArrayTy n           = A.ArrayTy(n, getpos())
let mkException s         = A.ExceptionDec(s, getpos())
@
\fi
%todo: inline? not much gain


% show example of dump! -dump_ast


\chapter{Checking}

% Typechecking and intermediate code generation are done together in tigerc
% (as opposed to ocaml where have typechecking returning a typed
% (and named) tree first). But fortunately things are well separated and most
% of the typechecking related functions are in Semantics and the
% intermediate code generation is in Trans.


%rappel:
%val translate : Environment.t -> Ast.exp -> (Frame.frame * Tree.exp) list

% the exp is actually the toplevel expression of the program

<<function Semantics.translate>>=
let translate env ast =
  let (mainex, mainty) = trexp env ast in

  if mainty <> INT && mainty <> UNIT 
  then E.type_err 0 "tiger program must return INT or UNIT";

  <<[[Semantics.translate()]] return translated functions>>
@
%less: rename main to top?
% type of mainex? Tree.exp
% generate final implicit "tiger_main" function for the final expression
%  (See the env created in new_env())
% alt: toplevel expr scheme of ocaml, not toplevel complex expr of C

%old:
%<<type Semantics.ast_node>>=
%type ast_node = 
% | DEC of Ast.dec 
% | EXP of Ast.exp
%@
% before had a trans function taking an env and 2 nested
% functions trdec and trexp taking env as closure, and 
% so you needed this ast_node intermediate type, but if you
% are more explicit and call trdec with an env, then you don't need
% trans and ast_node and it's arguably cleaner I think.

<<functions Semantics.trxxx>>=
<<function Semantics.trans.trexp>>
<<function Semantics.trans.trdec>>
<<function Semantics.trans.trvar>>
@

% spirit of the typechecker/generator is to go down recursively
% returning each time a pair with transformed ast and type of ast
% at this level

<<function Semantics.trans.trexp>>=
let rec trexp env = function
  <<[[Semantics.trans.trexp()]] cases>>
@


<<[[Semantics.trans.trexp()]] cases>>=
  | A.LetExp(decls, body, _) ->
      let env' = Env.new_scope env in
      let decs = decls |> List.map (fun d -> trdec env' d) in
      let bex,bty = trexp env' body in
      (Trans.sequence (decs @ [bex]), bty)
@ 
%less: why not call trdec here? because trdec does not take an env!


% code generation stuff, but important to see now.

<<[[Semantics.translate()]] return translated functions>>=
add_function (Env.frame env) (mainex, mainty);
List.rev !functions
@


<<global Semantics.functions>>=
let functions                 = ref []
@

<<function Semantics.add_function>>=
let add_function frm (ex,typ) =
  functions := (frm, Trans.func ex (is_ptr typ)) :: !functions
@
% nested functions are put in flat format here

%XXX
<<[[Environment.t]] other fields>>=
frame       : Frame.frame;
@

% Main.compile -> new_env -> <> (as frm <- add_function <- translate)
<<[[Environment.new_env()]] other field initializations>>=
frame       = F.new_frame (S.symbol "tiger_main") F.base_frame;
@




\section{The environment}

<<type Environment.t>>=
type t = {
    (* type definitions *)
    tenv        : vartype Symbol.table;
    (* value definitions *)
    venv        : vartype enventry Symbol.table;
    <<[[Environment.t]] other fields>>
  }
@
%note that symbol table are mutables!
%old: was 'a but clearer I think to put 'ty or even to directly
% reference vartype!

% need type definitions because local vars use typename and those
% typename are referenced in this tenv table.
% could be merged in venv? and have a TypeEntry?

<<type Environment.enventry>>=
type 'ty enventry =
    VarEntry of (Frame.access * 'ty)
  | FunEntry of (Tree.label * string option * Frame.frame * 'ty list * 'ty)
@ 
% label for labelization, frame for frameization
% string option = storage, for instance "C"
% Frame stuff again. codegen and typechecking mixed together.


% trexp (LexExp case)-> <>
<<function Environment.new_scope>>=
let new_scope env = { env with
                      tenv = S.new_scope env.tenv;
                      venv = S.new_scope env.venv }
@


\subsection{Lookups}

% 2 namespaces

<<signature function Environment.lookup_type>>=
val lookup_type  : t -> Ast.typename -> Ast.pos -> vartype
@
% why pos? to give error msg?

<<signature function Environment.lookup_value>>=
val lookup_value : t -> Ast.name -> Ast.pos -> vartype enventry
@

<<functions Environment.lookup_xxx>>=
let lookup env sym pos =
  try S.look env sym
  with Not_found ->
    raise(E.Error(E.Undefined_symbol (S.name sym), pos))

let lookup_type  env = lookup env.tenv
let lookup_value env = lookup env.venv
@

% actually there is a lookup_base_type which is similar to lookup_type
% but need it? shouldn't we have the invariant that tenv contains
% only expanded types?


\subsection{Enters}

<<signature function Environment.enter_type>>=
val enter_type  : t -> Ast.typename -> vartype -> unit
@

<<functions Environment.enter_xxx>>=
let enter tbl sym v =
  if S.mem tbl sym
  then raise(E.Error(E.Duplicate_symbol (S.name sym), 0))
  else S.enter tbl sym v

let enter_type env = enter env.tenv
@



<<signature function Environment.enter_fun>>=
val enter_fun   : 
  t -> Ast.name -> string option -> vartype list -> vartype  -> t
@
% not enter_global??
% this returns a new env because it's a new scope

<<functions Environment.enter_xxx>>=
let enter_fun env sym cc args result =
  let lbl = S.new_symbol (S.name sym) in
  let fenv = new_frame env lbl in

  let fe = FunEntry (lbl, cc, fenv.frame, args, result) in
  enter env.venv sym fe;
  fenv
@
% create a new scope
%less: use S.name here, so why needed a uid in the first place?

<<function Environment.new_frame>>=
let new_frame env sym = { env with
                          tenv = S.new_scope env.tenv;
                          venv = S.new_scope env.venv;
                          frame = Frame.new_frame sym env.frame;
                          exn_label = None }
@


% =~ gensym()
<<function Symbol.new_symbol>>=
let new_symbol prefix = 
  symbol (Printf.sprintf "%s_%d" prefix !nextsym)
@
% no incr nextsym?




<<signature function Environment.enter_param>>=
val enter_param : t -> Ast.name -> vartype -> Tree.is_ptr -> unit
@
<<signature function Environment.enter_local>>=
val enter_local : t -> Ast.name -> vartype -> Tree.is_ptr -> Frame.access
@
% is_ptr is useful info for the compilation (but not for typechecking)
% return unit because the info will be added in the frame of Env.t

<<function Environment.enter_param>>=
let enter_param env sym typ ptr =
  let access = F.alloc_param env.frame sym ptr in
  enter env.venv sym (VarEntry(access, typ))
@

<<function Environment.enter_local>>=
let enter_local env sym typ ptr =
  let access = F.alloc_local env.frame sym ptr in
  enter env.venv sym (VarEntry(access, typ));
  access
@
% will see alloc_xxx later

\section{Builtins}

% remember in Main.compile():
%  let base_env = Environment.new_env base_tenv base_venv in

<<constant Main.base_tenv>>=
let base_tenv =
(* name     type *)
[ "int",    T.INT
; "string", T.STRING
]
@

<<constant Main.base_venv>>=
let base_venv = 
(* name        cc        args                    return *)
[ "print",     Some "C", [T.STRING],             T.UNIT
; "printi",    Some "C", [T.INT],                T.UNIT
; "flush",     Some "C", [],                     T.UNIT
; "getchar",   None,     [],                     T.STRING
; "ord",       Some "C", [T.STRING],             T.INT
; "chr",       None,     [T.INT],                T.STRING
; "size",      Some "C", [T.STRING],             T.INT
; "sizea",     Some "C", [T.ARRAY T.ANY],        T.INT
; "substring", None,     [T.STRING;T.INT;T.INT], T.STRING
; "concat",    None,     [T.STRING;T.STRING],    T.STRING
; "not",       Some "C", [T.INT],                T.INT
; "exit",      Some "C", [T.INT],                T.UNIT
]
@

% Main.compile -> <>
<<function Environment.new_env>>=
let new_env types funs =
  let mkfe (n,cc,a,r) = (n, FunEntry(S.symbol n,cc,F.base_frame,a,r))
  in { tenv        = Symbol.create types;
       venv        = Symbol.create (List.map mkfe funs);

       <<[[Environment.new_env()]] other field initializations>>
       xenv        = Symbol.create [];
       break_label = None;
       exn_label   = None 
     }
@ 
% why need to keep also symbol in FunEntry?



\section{Typechecking helpers}


<<functions Semantics.check_type_xxx>>=
let check_type_t ty pos msg typ =
  if typ <> ty
  then E.type_err pos (msg ^ " must be of type " ^ type_name ty)

let check_type_int  = check_type_t INT
let check_type_unit = check_type_t UNIT
@ 


% trdec | ... -> <>
<<function Semantics.check_type_eq>>=
let check_type_eq pos msg t1 t2 =
  let are_equivalent = 
    match (t1,t2) with
    | (RECORD _,NIL)
    | (NIL,RECORD _)
    | (ARRAY ANY, ARRAY _)
    | (ARRAY _, ARRAY ANY) -> true
    | _                    -> t1 = t2
  in 
  if not are_equivalent
  then E.type_err pos (Printf.sprintf msg (type_name t1) (type_name t2))
@
%old: I reorged the code, clearer



\section{Definitions}

% translate -> trans -> <>
<<function Semantics.trans.trdec>>=
and trdec env = function
  <<[[Semantics.trans.trdec()]] cases>>
@
%old:
%  <<function declarations>>
%  <<variable declarations>>
%  <<type declarations>>
%  <<exception declarations>>

% remember LetExp case seen before


\subsection{Variables}
% globals and locals


<<[[Semantics.trans.trdec()]] cases>>=
| A.VarDec(name, typ, init, pos) ->
    let e,t = trexp env init in
    (match typ with
      Some x -> check_type_eq pos
          "Variable of type %s cannot be initialized with type %s"
          (Env.lookup_type env x pos) t
    | None -> ()
    );
    let access = Env.enter_local env name t (is_ptr t) in
    Trans.assign (Trans.simple_var (Env.frame env) access) e
@


\subsection{Types}

<<[[Semantics.trans.trdec()]] cases>>=
| A.TypeDec types ->
    let penv = Env.new_scope env in
    let real_type (name, typ, _) = 
      (name, 
       match typ with
       (* type expansion *)
       | A.NameTy(name, pos) -> Env.lookup_type penv name pos
       | A.RecordTy(fields) ->
          let chkfld(name,ty,p) = (name,(Env.lookup_type penv ty p))
          in RECORD (List.map chkfld fields)
       | A.ArrayTy(name, pos) -> ARRAY (Env.lookup_type penv name pos)
      )
    in
    types |> List.iter (fun(n,_,_) -> Env.enter_type penv n (NAME n));
    let real_types = (List.map real_type types) in
    real_types |> List.iter (fun (n,t) -> Env.enter_type env n t);
    Trans.nil
@
% mutually recursive types? how? can't inline forever :)
% so at least add NAME as default


\subsection{Functions}

<<[[Semantics.trans.trdec()]] cases>>=
| A.FunctionDec functions ->
    <<local function Semantics.trans.trdec.mk_param (for FunctionDec case)>>
    <<local function Semantics.trans.trdec.mk_func_env (for FunctionDec case)>>
    <<local function Semantics.trans.trdec.trans_func (for FunctionDec case)>>
    let envs = (List.map mk_func_env functions) in
    List.iter2 trans_func   envs functions;
    Trans.nil
@
% nil really?

<<local function Semantics.trans.trdec.trans_func (for FunctionDec case)>>=
let trans_func fenv (_, _, _, body, _) =
  let b = trexp fenv body in
  add_function (Env.frame fenv) b
in
@
% another function to translate


<<local function Semantics.trans.trdec.mk_func_env (for FunctionDec case)>>=
let mk_func_env (name, params, typ, _, pos) =
  let ret_type = 
    match typ with
    | Some x -> lookup_base_type env x pos
    | None   -> UNIT
  in
  let params_types = params|> List.map (fun(_,t,p)->lookup_base_type env t p) in
  let fenv  = Env.enter_fun env name None(*not C func*) params_types ret_type in
  params |> List.iter (fun p -> mk_param fenv p);
  fenv
in
@
% env here is enclosing env in trans.

<<local function Semantics.trans.trdec.mk_param (for FunctionDec case)>>=
let mk_param fenv (name, typ, pos) =
  let t = lookup_base_type env typ pos in
  Env.enter_param fenv name t (is_ptr t)
in
@

\section{Expressions}

%<<function Semantics.trans.trexp>>=
%and trexp = function
%  <<[[Semantics.trans.trexp()]] cases>>
%@
%old:
%  <<simple expressions>>
%  <<records>>
%  <<arrays>>
%  <<assignment>>
%  <<operator expressions(semantics.nw)>>
%  <<function calls(semantics.nw)>>
%  <<conditionals(semantics.nw)>>
%  <<loops(semantics.nw)>>
%  <<sequences(semantics.nw)>>
%  <<let expressions>>
%  <<exceptions(semantics.nw)>>
%  <<threads(semantics.nw)>>

\subsection{Literals}

<<[[Semantics.trans.trexp()]] cases>>=
  | A.NilExp         -> (Trans.nil,           NIL)
  | A.IntExp i       -> (Trans.int_literal i, INT)
  | A.StringExp(s,_) -> (Trans.str_literal s, STRING)
@

\subsection{Variable, array and field accesses}

<<[[Semantics.trans.trexp()]] cases>>=
  | A.VarExp v       -> trvar env v
@

<<function Semantics.trans.trvar>>=
and trvar env = function
  <<[[Semantics.trans.trvar()]] cases>>
@
%old:
%  <<simple vars>>
%  <<field vars>>
%  <<subscript vars>>

<<[[Semantics.trans.trvar()]] cases>>=
    A.SimpleVar(sym, pos) ->
      (match Env.lookup_value env sym pos with
        Env.VarEntry(access, vt) ->
          (Trans.simple_var (Env.frame env) access, base_type env vt)
      | Env.FunEntry _ ->
          E.type_err pos "function used as value"
      )
@
% no function as value :( Extension!!

<<[[Semantics.trans.trvar()]] cases>>=
  | A.FieldVar(var, sym, pos) ->
      let (exp, fields) = 
        match trvar env var with
        | (x, RECORD y) -> (x,y)
        | _ -> E.type_err pos "attempt to dereference non-record type"
      in
      let offset  = ref (-1) in
      let (_,fld) =
        try List.find (fun (s,v) -> incr offset; s = sym) fields
        with Not_found -> E.undefined pos (S.name sym)
      in
      let typ = base_type env fld in
      (Trans.field_var exp !offset (is_ptr typ), typ)
@
% offsetization here

<<[[Semantics.trans.trvar()]] cases>>=
  | A.SubscriptVar(var, exp, pos) ->
      let e,t = trexp env exp in
      check_type_int pos "subscript variable" t;
      (match trvar env var with
        (exp, ARRAY vt) ->
          let typ = (base_type env vt) in
          (Trans.subscript_var exp e (is_ptr typ) pos, typ)
      | _ ->
          E.type_err pos "attempt to dereference a non-array type"
      )
@

\subsection{Constructions}

<<[[Semantics.trans.trexp()]] cases>>=
  | A.RecordExp(var, fields, pos) ->
      <<function Semantics.trans.trexp.chk_field>>
      (match Env.lookup_type env var pos with
        RECORD dec_fields ->
          begin try
            let field_vals = (List.map2 chk_field fields dec_fields) in
            (Trans.new_record field_vals, RECORD dec_fields)
          with Invalid_argument s ->
            E.type_err pos "Record instance does not match declared type"
          end
      | _ ->
          E.type_err pos "Attempt to use non-record type as record"
      )
@

<<function Semantics.trans.trexp.chk_field>>=
let chk_field (s1,e,p) (s2,vt) =
  if (s1 <> s2) 
  then E.type_err p "field names do not match";
  let ex,ty = trexp env e in
  check_type_eq p "field type (%s) does not match declaration (%s)"
                  (base_type env vt) ty;
  (ex, is_ptr ty)
in
@


<<[[Semantics.trans.trexp()]] cases>>=
  | A.ArrayExp(name, size, init, pos) ->
      (match Env.lookup_type env name pos with
        ARRAY vt ->
          let size,sizety = trexp env size in
          let init,initty = trexp env init in
          let typ         = base_type env vt in
          check_type_int pos "array size" sizety;
          check_type_eq  pos "array type(%s) does not type(%s)" typ initty;
          (Trans.new_array size init (is_ptr typ), ARRAY vt)
      | _ ->
          E.type_err pos "Attempt to use a non-array type as an array"
      )
@


\subsection{Operators}

<<[[Semantics.trans.trexp()]] cases>>=
  | A.OpExp(left, oper, right, pos) ->
      let lexp,lty = trexp env left
      and rexp,rty = trexp env right in
      check_type_eq pos "Incompatible types %s,%s" lty rty;
      let trans_fn =
        match oper with
          A.PlusOp | A.MinusOp | A.TimesOp | A.DivideOp ->
            check_type_int pos "operator argument" lty;    Trans.arithmetic
        | A.EqOp | A.NeqOp
        | A.LtOp | A.LeOp | A.GtOp | A.GeOp ->
            (match lty with
              INT | NIL                                 -> Trans.compare_int
            | STRING                                    -> Trans.compare_str
            | ARRAY  _ when oper=A.EqOp || oper=A.NeqOp -> Trans.compare_int
            | RECORD _ when oper=A.EqOp || oper=A.NeqOp -> Trans.compare_int
            | _ ->
                E.type_err pos "Incomparable types"
            )
      in (trans_fn oper lexp rexp, INT)
@

\subsection{Function calls}

<<[[Semantics.trans.trexp()]] cases>>=
  | A.CallExp(sym, arglist, pos) ->
      let chk_arg = check_type_eq pos
                    "Argument type (%s) does not match declaration (%s)"
      in 
      (match Env.lookup_value env sym pos with
        Env.FunEntry(lbl, cc, frm, dec_args, return_type) ->
          let args,tys = List.split (List.map (trexp env) arglist) in
          begin try
            List.iter2 chk_arg tys dec_args;
            let rtyp = base_type env return_type in
            (Trans.call (Env.frame env) lbl cc frm args
                    (Env.exn_label env) (is_ptr rtyp), rtyp)
          with Invalid_argument x ->
            E.type_err pos "function arguments do not match declaration"
          end
      | _ ->
          E.type_err pos (S.name sym ^ " is not a function")
      )
@

\subsection{Local entity definitions}
% could be with definitions

% see above


\section{Statements}

\subsection{Sequence}

<<[[Semantics.trans.trexp()]] cases>>=
  | A.SeqExp ([],_) -> (Trans.nil, UNIT)
  | A.SeqExp (el,_) ->
      let exprs = List.rev_map (trexp env) el in
      let _,typ = List.hd exprs in
      let exprs = List.rev_map fst exprs in
      (Trans.sequence exprs, typ)
@

\subsection{Assignments}

<<[[Semantics.trans.trexp()]] cases>>=
  | A.AssignExp(var, exp, pos) ->
      let exp,ety = trexp env exp in
      let var,vty = trvar env var in
      check_type_eq pos "Cannot assign to type %s from type %s" vty ety;
      (Trans.assign var exp, UNIT)
@

\subsection{Conditionals}

<<[[Semantics.trans.trexp()]] cases>>=
  | A.IfExp(if', then', else', pos) ->
      let iex,ity = trexp env if' in
      let tex,tty = trexp env then' in
      let eex,ety = 
         match else' with
         | None    -> (Trans.nil, UNIT)
         | Some ex -> trexp env ex
      in
      check_type_int pos "if condition" ity;
      check_type_eq  pos
        "type of then expression (%s) does not match else (%s)" tty ety;
      let typ = base_type env tty in
      (Trans.ifexp iex tex eex (is_ptr typ), typ)
@

\subsection{Loops}

<<[[Environment.t]] other fields>>=
break_label : Tree.label option;
@
% for labelization algorithm

<<[[Semantics.trans.trexp()]] cases>>=
  | A.WhileExp(test, body, pos) ->
      let tex,tty = trexp env test in
      let body_env = Env.new_break_label env in
      let bex,bty = trexp body_env body in
      check_type_int pos "while condition" tty;
      check_type_eq  pos "body of while has type %s, must be %s" bty UNIT;
      (Trans.loop tex bex (Env.break_label body_env), UNIT)
@

<<[[Semantics.trans.trexp()]] cases>>=
  | A.BreakExp pos ->
      begin
        try (Trans.break (Env.break_label env), UNIT)
        with Not_found -> raise(E.Error(E.Illegal_break, pos))
      end
@


<<[[Semantics.trans.trexp()]] cases>>=
  | A.ForExp(sym, lo, hi, body, pos) ->
      let _,loty = trexp env lo in
      let _,hity = trexp env hi in
      check_type_int pos "for lower bound" loty;
      check_type_int pos "for upper bound" hity;
     <<[[Semantics.trans.trexp()]] ForExp case, unsugaring for in while>>
@








\chapter{Intermediate Representation Generation}
%IR generation

% Here we will compile:
% - "labelization"
% - "offsetization"
% - "frameization"
% - "layouting"?
% - "linearization"


\section{Function definitions}

<<signature functions Translate.xxx>>=
val func          : Tree.exp -> Tree.is_ptr -> Tree.exp
@
<<function Translate.func>>=
let func ex ptr =
  let tmp = temp ptr in
  eseq nil [ex => tmp; T.RET tmp]
@
% function foo() { 1 } ==> tmp_ = 1; return tmp_
%less: rename func_body? 
%less: need eseq? could just finish with a RET no? no because
% most of our function need to return a Tree.exp, not a Tree.stm
%old: use to take a frame, but was unused

%\section{Helpers}

<<function Translate.temp>>=
let temp ptr = 
  T.TEMP (T.new_temp(), ptr)
@
<<function Tree.new_temp>>=
let new_temp () = 
  S.new_symbol "temp"
@

<<function Translate.eseq>>=
let eseq exp stmts = 
  T.ESEQ (seq stmts, exp)
@
% expression sequence

<<function Translate.seq>>=
let rec seq = function
    []        -> E.internal "nil passed to seq"
  | x :: []   -> x
  | x :: rest -> T.SEQ(x, seq rest)
@ 
% statement sequence

\section{Expressions}

\subsection{Literals}

<<signature functions Translate.xxx>>=
val nil           : Tree.exp
val int_literal   : int -> Tree.exp
val str_literal   : string -> Tree.exp
@
<<functions Translate.xxx literals>>=
let nil           = T.CONST 0
let int_literal i = T.CONST i
let str_literal s = T.NAME (F.alloc_string s)
@

% which globals does alloc_string modifies? Frame.strings
% and then see code generation about output_strings()

<<global Frame.strings>>=
let strings = H.create 20
@
<<function Frame.alloc_string>>=
let alloc_string s =
  try H.find strings s
  with Not_found ->
    let lbl = T.new_label "gbl" in
    (H.add strings s lbl; lbl)
@
%hmm opti where same strings are shared, but if can allow people
% to modify the strings, then pb! because shared.

\subsection{Field, array and offsetization}

<<signature functions Translate.xxx>>=
val field_var     : Tree.exp -> int -> Tree.is_ptr -> Tree.exp
@
<<function Translate.field_var>>=
let field_var ex i ptr = T.MEM(ex <+> T.CONST(i * ws), ptr)
@ 
% has already done offsetization in caller 
% (but assume all fields have the same width, hmmm)

<<function Translate.angles_xxx>>=
let (<+>) = simplify T.PLUS  ( + )
let (<->) = simplify T.MINUS ( - )
let (<*>) = simplify T.MUL   ( * )
@

% a form of opti, partial evaluation
<<function Translate.simplify>>=
let simplify tig_op op = 
 fun x y ->
  match (x,y) with
    (T.CONST x, T.CONST y) -> T.CONST (op x y)
  | _                      -> T.BINOP (tig_op, x, y)
@

<<constant Translate.ws>>=
let  ws    = Sys.word_size / 8
@
%less: hmm size in bytes so rename wsb?




<<signature functions Translate.xxx>>=
val subscript_var : Tree.exp -> Tree.exp -> Tree.is_ptr -> int -> Tree.exp
@
<<function Translate.subscript_var>>=
let subscript_var e1 e2 ptr pos =
  let check = ext_c_call "bounds_check"
                        [e1;e2;T.CONST(fst (Error.line_number pos))] in
  let offset = (e2 <+> T.CONST 1) <*> T.CONST ws in
  eseq (T.MEM(e1 <+> offset, ptr)) [T.EXP check]
@



\subsection{Variable and frameization}

<<signature functions Translate.xxx>>=
val simple_var    : Frame.frame -> Frame.access -> Tree.exp
@
<<function Translate.simple_var>>=
let simple_var frm = function
  | F.Stack(var_frm, offset, ptr) ->
      T.MEM(getfp frm var_frm <+> T.CONST(offset * ws), ptr)
@ 
%old:  | F.Temp lbl ->   T.NAME lbl

% alloc_xxx
<<type Frame.access>>=
type access =
    Stack of frame * int * Tree.is_ptr
@
%old:  | Temp  of Tree.label
% but useless because can't have Temp in Translation phase.

% Semantics.trans.trdec -> Environment.enter_local -> <>
<<function Frame.alloc_local>>=
let alloc_local frm name ptr =
  frm.vars <- (name,ptr) :: frm.vars;
  stack_alloc frm ptr
@
% Semantics.trans.trdec.mk_param -> Environment.enter_param -> <>
<<function Frame.alloc_param>>=
let alloc_param frm name ptr =
  frm.params <- frm.params @ [(name,ptr)];
  stack_alloc frm ptr
@

<<function Frame.stack_alloc>>=
let stack_alloc frm ptr =
  let v = Stack(frm, frm.size, ptr) in
  frm.size <- frm.size + 1; 
  v
@

<<[[Frame.frame]] other fields>>=
mutable size   : int;
@
%todo: who will use that?


<<function Translate.getfp>>=
let getfp frm parent_frm =
  let diff = F.level frm  - F.level parent_frm in
  let rec deref = function
      0 -> F.fp frm
    | x -> T.MEM (deref (x-1), true)
  in 
  assert (diff >= 0);
  deref diff
@
% nested function!

<<function Frame.fp>>=
let fp    frm = 
  T.NAME (S.symbol "fp")
@



\subsection{Constructions and allocations}

<<signature functions Translate.xxx>>=
val new_record    : (Tree.exp * Tree.is_ptr) list -> Tree.exp
val new_array     : Tree.exp -> Tree.exp -> Tree.is_ptr -> Tree.exp
@

<<function Translate.new_record>>=
let new_record init =
  let tmp  = temp true in
  let size = T.CONST (List.length init) in
  let rec initialize offset = function
      []             -> []
    | (ex,ptr)::rest -> (ex => field_var tmp offset ptr)
                        :: initialize (offset+1) rest
  in
  eseq tmp ((alloc size => tmp) :: initialize 0 init)
@
% we will see alloc() later in Runtime chapter.


<<function Translate.new_array>>=
let new_array sizeEx initEx ptr = 
  let ary  = temp true in
  let i    = temp false in
  let lbeg = T.new_label "init_start" in
  let lend = T.new_label "init_end" in
  eseq ary
    [ alloc (sizeEx <+> T.CONST 1) => ary;
      sizeEx => T.MEM(ary, false);
      T.CONST 1 => i;
      T.LABEL lbeg;
      initEx => T.MEM (ary <+> (i <*> T.CONST ws), ptr);
      i <+> T.CONST 1 => i;
      T.CJUMP(T.RELOP(T.LE, i, sizeEx <+> T.CONST 1), lbeg, lend);
      T.LABEL lend ]
@
% sizeEx + 1? why?

% dynamic arrays!

\subsection{Operators}

<<signature functions Translate.xxx>>=
val arithmetic    : Ast.oper -> Tree.exp -> Tree.exp -> Tree.exp
val compare_int   : Ast.oper -> Tree.exp -> Tree.exp -> Tree.exp
val compare_str   : Ast.oper -> Tree.exp -> Tree.exp -> Tree.exp
@

\subsection{Function calls}

<<signature functions Translate.xxx>>=
val call          : 
  Frame.frame -> Tree.label -> string option -> Frame.frame -> 
  Tree.exp list -> Tree.label option -> Tree.is_ptr -> 
  Tree.exp
@
<<function Translate.call>>=
let call myfrm lbl cc frm args k ptr =
  let args =
    if F.level frm == 0 
    then args
    else 
      let pfp =
        if (F.level frm) > (F.level myfrm) 
        then F.fp frm
        else T.MEM(getfp myfrm frm, true)
      in 
      pfp  :: args
  in
  match cc with
    None        -> T.CALL((T.NAME lbl), args, cc, k, ptr)
  | Some "gc"   -> T.CALL((T.NAME lbl), args, cc, k, ptr)
  | Some _ ->
      let tmp1      = temp ptr
      and tmp2      = temp ptr
      in eseq tmp2 [ T.MOVE(alloc_ptr, tmp1);
                     T.MOVE(T.CALL((T.NAME lbl), args, cc, k, ptr), tmp2);
                     T.MOVE(tmp1, alloc_ptr) ]
@



<<functions Translate.ext_xxx_call>>=
let ext_call cc name args =
  call F.base_frame (S.symbol name) cc
       F.base_frame args None false

let ext_c_call   = ext_call (Some "C")
let ext_gc_call  = ext_call  None (* (Some "gc") *)
let ext_cmm_call = ext_call  None
@

\section{Statements and labelization}

\subsection{Sequence}

<<signature functions Translate.xxx>>=
val sequence      : Tree.exp list -> Tree.exp
@

<<function Translate.sequence>>=
let rec sequence = function
   []       -> nil
  | e :: [] -> e
  | e :: es -> T.ESEQ((T.EXP e), (sequence es))
@

\subsection{Assignments}

<<signature functions Translate.xxx>>=
val assign        : Tree.exp -> Tree.exp -> Tree.exp
@
<<function Translate.assign>>=
let assign v e = 
  eseq nil [e => v]
@

\subsection{Conditionals}

% note that if are expressions in Tiger!

<<signature functions Translate.xxx>>=
val ifexp         : Tree.exp -> Tree.exp -> Tree.exp -> Tree.is_ptr -> Tree.exp
@

<<function Translate.ifexp>>=
let ifexp test thn els ptr =
  let tmp  = temp ptr in
  let tru  = T.new_label "ifTrue" in
  let fls  = T.new_label "ifFalse" in
  let end' = T.new_label "ifEnd" in
  eseq tmp [ T.CJUMP(test, tru, fls);
             T.LABEL tru; thn => tmp; goto end';
             T.LABEL fls; els => tmp;
             T.LABEL end']
@
% nice looking code


\subsection{Loops}


<<[[Semantics.trans.trexp()]] ForExp case, unsugaring for in while>>=
 let v            = A.SimpleVar(sym, pos) in
 let ve           = A.VarExp v in
 trexp env 
   (A.LetExp(
        [(A.VarDec(sym,(Some(S.symbol "int")), lo, pos))],
        (A.WhileExp
           (A.OpExp(ve, A.LeOp, hi, pos),
            (A.SeqExp([body;
                      (A.AssignExp(v, 
                         A.OpExp(ve, A.PlusOp, (A.IntExp 1), pos), pos))
                      ], pos)),
            pos)),
        pos))
@
%less: hmm recompute hi each time?
% opti opportunity here! if complex expression that does not change
% can precompute it once and for all





<<signature functions Translate.xxx>>=
val loop          : Tree.exp -> Tree.exp -> Tree.label -> Tree.exp
@

% for while and for (unsugared in while)
<<function Translate.loop>>=
let loop test body lend = 
  let lbeg = T.new_label "loop_start"
  and lbdy = T.new_label "loop_body" in
  eseq nil [ T.LABEL lbeg;
             T.CJUMP(test, lbdy, lend);
             T.LABEL lbdy; T.EXP body; goto lbeg;
             T.LABEL lend ]
@

<<signature functions Translate.xxx>>=
val break         : Tree.label -> Tree.exp
@
<<function Translate.break>>=
let break lbl = eseq nil [goto lbl]
@


\section{Statements, expressions and linearization}

% here we will compile:
% - complex expressions to basic 3 address like code


% compile -> emit_function -> <>
<<function Canonical.linearize>>=
let linearize stm0 =

  let rec reorder = function
      T.CALL(_,_,_,_,ptr) as call :: rest ->
        let t = T.TEMP(T.new_temp(), ptr)
        in reorder(T.ESEQ(T.MOVE(call, t), t) :: rest)
    | a :: rest ->
        let (stms,e) = do_exp a
        and (stms',el) = reorder rest in
        if commute(stms',e)
        then (stms % stms',e::el)
        else let t = T.TEMP(T.new_temp(), T.is_ptr e) in 
        (stms % T.MOVE(e, t) % stms', t :: el)
    | [] -> (nop,[])

  and reorder_exp(el,build) = 
    let (stms,el') = reorder el
    in (stms, build el')

  and reorder_stm(el,build) =
    let (stms,el') = reorder el
    in stms % (build el')

  and do_stm = function
      T.SEQ(a,b) ->
        do_stm a % do_stm b
    | T.JUMP e ->
        let f l = T.JUMP (List.hd l)
        in reorder_stm([e], f)
    | T.CJUMP(e,t,f) ->
        let f l = T.CJUMP(List.hd l, t, f)
        in reorder_stm([e], f)
    | T.MOVE(T.CALL(e,el,ext,k,ptr),T.TEMP(t,_)) ->
        let f l = T.MOVE(T.CALL(List.hd l, List.tl l, ext, k, ptr), T.TEMP(t,ptr))
        in reorder_stm(e :: el, f)
    | T.MOVE(b,T.TEMP(t,ptr)) ->
        let f l = T.MOVE(List.hd l, T.TEMP(t,ptr))
        in reorder_stm([b], f)
    | T.MOVE(b,T.NAME n) ->
        let f l = T.MOVE(List.hd l, T.NAME n)
        in reorder_stm([b], f)
    | T.MOVE(T.ESEQ(s,e), b) ->
        do_stm(T.SEQ(s,T.MOVE(e,b)))
    | T.MOVE(b,T.MEM(e,ptr)) ->
        let f l = T.MOVE(List.hd l, T.MEM(List.nth l 1, ptr))
        in reorder_stm([b ; e], f)
    | T.MOVE(b,T.ESEQ(s,e)) ->
        do_stm(T.SEQ(s,T.MOVE(b,e)))
    | T.EXP(T.CALL(e,el,ext,k,ptr)) ->
        let f l = T.EXP(T.CALL(List.hd l, List.tl l, ext, k, ptr))
        in reorder_stm(e :: el, f)
    | T.EXP e ->
        let f l = T.EXP (List.hd l)
        in reorder_stm([e], f)
    | s ->
        let f l = s
        in reorder_stm([], f)

  and do_exp = function
      T.BINOP(p,a,b) ->
        let f l = T.BINOP(p, List.hd l, List.nth l 1)
        in reorder_exp([a ; b], f)
    | T.RELOP(p,a,b) ->
        let f l = T.RELOP(p, List.hd l, List.nth l 1)
        in reorder_exp([a ; b], f)
    | T.MEM(a,ptr) ->
        let f l = T.MEM (List.hd l,ptr)
        in reorder_exp([a], f)
    | T.ESEQ(s,e) ->
        let stms = do_stm s
        and (stms',e) = do_exp e
        in (stms%stms',e)
    | T.CALL(e,el,ext,k,ptr) ->
        let f l = T.CALL(List.hd l, List.tl l, ext, k, ptr)
        in reorder_exp(e :: el, f)
    | e ->
        let f l = e
        in reorder_exp([], f)

  (* linear gets rid of the top-level SEQ's, producing a list *)
  and linear = function
      (T.SEQ(a,b),l) -> linear(a,linear(b,l))
    | (s,l) -> s :: l

 in 
 (* body of linearize *)
 linear(do_stm stm0, [])
@

<<function Canonical.commute>>=
let commute = function
    (T.EXP(T.CONST _), _) -> true
  | (_, T.NAME _) -> true
  | (_, T.CONST _) -> true
  | _ -> false
@

<<function Canonical.percent>>=
let ( % ) x y =
  match (x,y) with
    (T.EXP(T.CONST _), _) -> y
  | (_, T.EXP(T.CONST _)) -> x
  | _ -> T.SEQ(x,y)

@

<<constant Canonical.nop>>=
let nop = T.EXP(T.CONST 0)
@



<<[[Main.emit_function()]] adjust frm with temporaries in ltree>>=
ltree |> Tree.find_temps |> List.iter (fun (x,p) -> 
  Frame.alloc_temp frm x p
);
@

<<signature function Tree.find_temps>>=
val find_temps : stm list -> (temp * is_ptr) list
@
%why do that at the end? why not call those alloc_temp before?


\chapter{[[C--]] Generation}

\section{File header}

<<[[Main.compile()]] generate headers>>=
Codegen.output_file_header imports;
@

\section{Data}

% main -> compile -> <>
<<[[Main.compile()]] generate data before functions>>=
Frame.output_strings();
@

\section{Function header}

% main -> compile -> emit_function -> <>

\section{Function body}

\section{Function footer}

% main -> compile -> emit_function -> <>




\chapter{Runtime}

\section{Standard library}

\section{Startup code}

\section{Memory allocation}

%less: mv later when talk about gc?
% (Translate.new_record | Translate.new_array) -> <>
<<function Translate.alloc>>=
let alloc size =
  let size = (size <+> T.CONST 1) <*> T.CONST ws in
  let test = T.RELOP(T.GT, alloc_ptr <+> size, space_end) in
  let tmp  = temp true in
  let tru  = T.new_label "alc_gc" in
  let fls  = T.new_label "alc" in
  eseq tmp [ T.CJUMP(test, tru, fls);
             T.LABEL tru; T.EXP (ext_gc_call "call_gc" []);
             T.LABEL fls;
             size => T.MEM(alloc_ptr, true);
             (alloc_ptr <+> T.CONST ws) => tmp;
             (alloc_ptr <+> size) => alloc_ptr
            ]
@
%                (* ; T.EXP (ext_gc_call "call_gc" []) *)
% GC interface here!!

\section{Garbage collection}


\chapter{Advanced Features}

\section{Typedefs}

<<[[Environment.vartype]] cases>>=
| NAME   of Ast.typename
@
% actually necessary to support mutually recursive type too!


<<function Semantics.base_type>>=
let rec base_type env = function
    NAME s ->
      (try base_type env (Env.lookup_type env s 0)
       with Not_found -> E.internal "NAME symbol not found"
      )
  | x -> x
@

<<function Semantics.lookup_base_type>>=
let lookup_base_type env sym pos =
  base_type env (Env.lookup_type env sym pos)
@ 

\section{Exceptions}

%lexer
<<token declarations>>=
%token EXCEPTION  TRY RAISE HANDLE
@

<<[[Lexer.keyword_table]] entries>>=
"exception", P.EXCEPTION;

"try",       P.TRY;
"handle",    P.HANDLE;
"raise",     P.RAISE;
@



%AST def
<<[[Ast.dec]] cases>>=
| ExceptionDec of name * pos
@

%grammar def
<<rule exn_dec>>=
exn_dec:
   EXCEPTION id { mkException $2 }
@
%$
% no arguments in exception

% AST use
<<[[Ast.exp]] cases>>=
| TryExp    of exp * (name * exp * pos) list * pos
| RaiseExp  of name * pos
@

% grammar user
<<rule expr>>=
 | TRY expr handlers         { mkTryExp $2 (List.rev $3) }
 | RAISE id                  { mkRaise $2 }
@
%$

<<subrules for stmt>>=
/* exception handlers */
handler:
   HANDLE id expr END         { mkHandler $2 $3 }

handlers:
   handler          { $1 :: [] }
 | handler handlers { $1 :: $2 }
@
%$


% typechecking
<<[[Environment.t]] other fields>>=
exn_label   : Tree.label option;
@
% remember that reset to None in new_frame, each time translate
% a new function

<<[[Environment.t]] other fields>>=
xenv        : int Symbol.table;
@

<<signature function Environment.lookup_exn>>=
val lookup_exn   : t -> Ast.name -> Ast.pos -> int
@
<<functions Environment.lookup_xxx>>=
let lookup_exn   env = lookup env.xenv
@

<<signature function Environment.enter_exn>>=
val enter_exn   : t -> Ast.name -> unit
@
<<functions Environment.enter_xxx>>=
let enter_exn env sym = enter env.xenv sym (S.uid sym)
@

<<[[Semantics.trans.trdec()]] cases>>=
  | A.ExceptionDec(sym,_) -> Env.enter_exn env sym; Trans.nil
@

<<[[Semantics.trans.trexp()]] cases>>=
  | A.TryExp(expr, handlers, pos) ->
      let new_env         = Env.new_exn_label env in
      let tryex, tryty    = trexp new_env expr in
      let handler (s,h,p) =
        let ex,ty = trexp env h in
        check_type_unit p "handler" ty;
        (S.uid s, ex)
      in
      check_type_unit pos "try" tryty;
      begin match Env.exn_label new_env with
        None     -> E.internal "no exception label for try block"
      | Some lbl ->
          (Trans.try_block tryex lbl (List.map handler handlers), tryty)
      end
@ 

<<[[Semantics.trans.trexp()]] cases>>=
  | A.RaiseExp(sym, pos) ->
      let exn_id = Env.lookup_exn env sym pos in
      (Trans.raise_exn exn_id, UNIT)
@


% generating
<<[[Tree.stm]] cases>>=
  | CONT   of label * label list
  | TRY    of label
  | TRYEND of label
@

<<signature functions Translate.xxx>>=
val try_block     : Tree.exp -> Tree.label -> (int *Tree.exp) list -> Tree.exp
val raise_exn     : int -> Tree.exp
@

<<function Translate.try_block>>=
let try_block exp exn_lbl hs =
  let cont l = function
      T.TEMP(t,_) -> T.CONT(l, [t])
    | _           -> E.internal "non temp in continuation node"
  in
  let try_endl         = T.new_label "try_end"
  and tmp              = temp false in
  let handler (uid,ex) =
    let hl = T.new_label "handle"
    and sl = T.new_label "skip" in
    [ T.CJUMP(T.RELOP(T.EQ, tmp, T.CONST uid), hl, sl);
      T.LABEL hl; T.EXP ex; goto try_endl;
      T.LABEL sl ]
  in
  let old            = temp false in
  let set_handler    = ext_cmm_call "set_handler" [T.NAME exn_lbl] => old
  and reset_handler  = T.EXP (ext_cmm_call "set_handler" [old])
  and not_unwind stm = if !Option.unwind then T.EXP nil else stm
  in
  eseq tmp [ T.TRY exn_lbl;
             not_unwind set_handler;
             exp => tmp;
             not_unwind reset_handler;
             T.TRYEND exn_lbl;
             goto try_endl;
             cont exn_lbl tmp;
             not_unwind reset_handler;
             seq (List.flatten (List.map handler hs));
             T.LABEL try_endl ]

@ 

<<function Translate.raise_exn>>=
let raise_exn uid =
  let fn = if !Option.unwind then "unwind" else "raise" in
  ext_cmm_call fn [T.CONST uid]
@


<<command line flags>>=
let unwind = ref false
@
<<command line options>>=
"-unwind",   Arg.Set unwind, "\tuse unwind continuations for exceptions";
@


\section{Spawn}
% threads. But this is supported by c-- for free.

%AST
<<[[Ast.exp]] cases>>=
| SpawnExp  of name * pos
@

%lexer
<<token declarations>>=
%token SPAWN
@
<<[[Lexer.keyword_table]] entries>>=
"spawn",     P.SPAWN;
@

%grammar
<<rule expr>>=
 | SPAWN id                  { mkSpawn $2 }
@
%$

%typechecking
<<[[Semantics.trans.trexp()]] cases>>=
  | A.SpawnExp(sym, pos) ->
      (match Env.lookup_value env sym pos with
        Env.FunEntry(lbl, cc, frm, dec_args, return_type) ->
          if dec_args <> []
          then E.type_err pos "spawn function must take zero arguments."
          else (Trans.spawn lbl, INT)
      | _ ->
          E.type_err pos (S.name sym ^ " is not a function")
      )
@

% generating
<<signature functions Translate.xxx>>=
val spawn         : Tree.label -> Tree.exp
@
<<function Translate.spawn>>=
let spawn lbl = ext_cmm_call "spawn" [T.NAME lbl]
@



\chapter{Advanced Topics}

\chapter{Conclusion}




\appendix

\chapter{Error Managment}

\section{The errors}

<<type Error.error>>=
type error =
    Internal_error of string

  (* lexical errors *)
  | Illegal_character of char
  | Illegal_escape of string
  | Unterminated_comment
  | Unterminated_string

  (* syntaxic errors *)
  | Syntax_error

  (* semantic errors *)
  | Type_error of string
  | Undefined_symbol of string
  | Duplicate_symbol of string
  | Illegal_break
@
%less: rename error_kind

<<type Error.ex>>=
type ex = error * int
@
%less: rename just error, because ex means?

<<exception Error.Error>>=
exception Error of ex
@

%ex:
<<parser helper functions>>=
let parse_error s =
  let pos = getpos() in
  raise (E.Error(E.Syntax_error, pos))
@

<<function Error.type_err>>=
let type_err  pos msg = 
  raise(Error(Type_error msg, pos))
@
<<function Error.undefined>>=
let undefined pos msg = 
  raise(Error(Undefined_symbol msg, pos))
@
<<function Error.internal>>=
let internal      msg = 
  raise(Error(Internal_error msg, 0))
@

<<function Error.handle_exception>>=
let handle_exception (ex,pos) =
  let msg = match ex with
    Internal_error s     -> "Compiler bug: " ^ s

  | Illegal_character ch -> Printf.sprintf "illegal character '%c'" ch
  | Illegal_escape str   -> Printf.sprintf "illegal escape %s" str
  | Unterminated_comment -> "unterminated comment"
  | Unterminated_string  -> "unterminated string"

  | Syntax_error         -> "syntax error"

  | Type_error str       -> str
  | Undefined_symbol str -> "undefined symbol: " ^ str
  | Duplicate_symbol str -> "duplcate definition of: " ^ str
  | Illegal_break        -> "Illegal break statement"
  in
  err_msg "Error" pos msg;
  exit 1
@

% type error dumper, should be the string in Type_error of string above
<<function Semantics.type_name>>=
let rec type_name = function
    RECORD l -> (List.fold_left (fun x y -> x ^ (type_name (snd y)))
                "record {" l) ^ "}"
  | NIL      -> "nil"
  | INT      -> "int"
  | STRING   -> "string"
  | ARRAY vt -> "array of " ^ (type_name vt)
  | NAME(s)  -> "named type " ^ (S.name s)
  | UNIT     -> "unit"
  | ANY      -> "any"
@ 

\section{Line position}

<<function Error.err_msg>>=
let err_msg prefix pos msg =
  let (line,col) = line_number pos in
  if line > 0 
  then
    Printf.fprintf stderr
      "%s:%d,%d: %s\n" !Option.file line col msg
  else
    Printf.fprintf stderr "%s: %s\n" prefix msg
@

<<function Error.warning>>=
let warning = err_msg "Warning"
@


<<function Error.line_number>>=
let line_number pos =
  let rec line ln last_p = function
      (p,l) :: rest ->
        if p > pos then (l, pos - last_p)
        else line l p rest
    | [] -> (ln + 1, pos - last_p)
  in line 0 0 source_map.sm
@



% source map
<<type Error.sm>>=
type sm = { mutable sm: (int * int) list }
@

<<global Error.source_map>>=
let source_map = { sm = [(0,0)] }
@

% should be called by the lexer
<<function Error.add_source_mapping>>=
let add_source_mapping pos line =
  source_map.sm <- source_map.sm @ [(pos,line)]
@
% @? slow?





\chapter{Debugging}

\section{[[tiger -dump_ast]]}

<<command line flags>>=
let dump_ast    = ref false
@
<<command line options>>=
"-dump_ast",      Arg.Set dump_ast,    "\tprint Abstract Syntax Tree";
@

<<[[Main.compile()]] if dump AST option>>=
if !Option.dump_ast
then Ast.print_tree ast;
@


<<function Ast.print_tree>>=
let print_tree expression =
  <<declaration printer>>
  <<type printer>>
  <<variable printer>>
  <<expression printer>>
in exp 0 expression
@

<<function iprintf>>=
let iprintf d fmt =
  let rec indent = function
      0 -> ()
    | i -> (print_string "  "; indent(i-1))
  in (indent d; Printf.printf fmt)
@



<<declaration printer>>=
let rec dec d =
  let print_opt_sym d = function
      None   -> iprintf (d+1) ": NONE\n"
    | Some s -> iprintf (d+1) ": SOME(%s)\n" (S.name s)
  in
  function
    FunctionDec functions ->
      let prfield d (n,t,_) =
        iprintf d "%s:%s\n" (S.name n) (S.name t)
      in
      let prfun d (name, params, type', body, _) =
 iprintf d "%s:\n" (S.name name);
        List.iter (prfield (d+1)) params;
        print_opt_sym (d+1) type';
 exp (d+2) body
      in
      iprintf d "FunctionDec:\n";
      List.iter (prfun (d+1)) functions
  | VarDec(name, type', init,_) ->
      iprintf d "VarDec: %s\n" (S.name name);
      print_opt_sym (d+1) type';
      exp (d+1) init
  | TypeDec types ->
      let prtdec d (name, type',_) =
        iprintf d "%s:\n" (S.name name); ty (d+1) type'
      in
      iprintf d "TypeDec:\n";
      List.iter (prtdec (d+1)) types
  | ExceptionDec(s,_) ->
      iprintf d "ExceptionDec:%s\n" (S.name s)
@
<<type printer>>=
and ty d = function
    NameTy(s,_)     -> iprintf d "NameTy : %s\n" (S.name s)
  | ArrayTy(s,_)    -> iprintf d "ArrayTy: %s\n" (S.name s)
  | RecordTy fields ->
      let f d (n,t,_) =
        iprintf d "%s:%s\n" (S.name n) (S.name t)
      in
      iprintf d "RecordTy:\n";
      List.iter (f (d+1)) fields
@
<<variable printer>>=
and var d = function
    SimpleVar(s,_)      -> iprintf d "SimpleVar: %s\n" (S.name s)
  | FieldVar(v,s,_)     -> iprintf d "FieldVar:\n";
                           var (d+1) v;
                           iprintf (d+1) "%s\n" (S.name s)
  | SubscriptVar(v,e,_) -> iprintf d "SubscriptVar:\n";
                           var (d+1) v;
                           exp (d+1) e
@
<<expression printer>>=
and exp d = function
    VarExp v       -> var d v
  | NilExp         -> iprintf d "NilExp\n"
  | IntExp i       -> iprintf d "IntExp: %d\n" i
  | StringExp(s,_) -> iprintf d "StringExp:%s\n" (String.escaped s)
  | RecordExp(name, fields, _) ->
      let f d (n,e,_) =
        (iprintf d "%s:\n" (S.name n); exp (d+1) e)
      in
      iprintf d "RecordExp: %s\n" (S.name name);
      List.iter (f (d+1)) fields
  | ArrayExp(v, size, init, p) ->
      iprintf d "ArrayExp: %s\n" (S.name v);
      exp (d+1) size;
      exp (d+1) init
  | AssignExp(v, e, _) ->
      iprintf d "AssignExp:\n";
      var (d+1) v;
      exp (d+1) e
  | OpExp(left, oper, right, _) -> 
      iprintf d "OpExp:%s\n" (opname oper);
      exp (d+1) left;
      exp (d+1) right
  | CallExp(name, args, _) ->
      iprintf d "CallExp: %s\n" (S.name name);
      List.iter (exp (d+1)) args
  | IfExp(if', then', else', _) ->
      iprintf d "IfExp:\n";
      exp (d+1) if';
      exp (d+1) then';
      begin match else' with
        None   -> ()
      | Some a -> exp (d+1) a
      end
  | WhileExp(test, body, _) ->
      iprintf d "WhileExp:\n";
      exp (d+1) test;
      exp (d+1) body
  | ForExp(var, lo, hi, body, _) ->
      iprintf d "ForExp: %s\n" (S.name var);
      exp (d+1) lo;
      exp (d+1) hi;
      exp (d+1) body
  | BreakExp _ ->
      iprintf d "BreakExp\n"
  | SeqExp(l, _) ->
      iprintf d "SeqExp:\n"; List.iter (exp (d+1)) l
  | LetExp(decs, body, _) ->
      iprintf d "LetExp:\n";
      List.iter (dec (d+1)) decs;
      iprintf d "IN:\n";
      exp (d+2) body
  | TryExp(expr, handlers, _) ->
      iprintf d "TryExp:\n";
      exp (d+1) expr;
      List.iter
        (fun (n,h,_) -> iprintf (d+2) "%s:\n" (S.name n); exp (d+2) h)
        handlers
  | RaiseExp(name,_) ->
      iprintf d "RaiseExp %s\n" (S.name name)
  | SpawnExp(name,_) ->
      iprintf d "SpawnExp %s\n" (S.name name)
@ 

<<function Ast.opname>>=
let opname = function
    PlusOp   -> "PlusOp"
  | MinusOp  -> "MinusOp"
  | TimesOp  -> "TimesOp"
  | DivideOp -> "DivideOp"
  | EqOp     -> "EqOp"
  | NeqOp    -> "NeqOp"
  | LtOp     -> "LtOp"
  | LeOp     -> "LeOp"
  | GtOp     -> "GtOp"
  | GeOp     -> "GeOp"
@


\section{[[tiger -dump_ext]]}

<<command line flags>>=
let dump_ext    = ref false
@
<<command line options>>=
"-dump_ext",      Arg.Set dump_ext,    "\tprint Expression Trees";
@

<<[[Main.emit_function()]] if dump expression tree>>=
if !Option.dump_ext  
then Tree.print_exp ex;
@


<<function Tree.print_exp>>=
let print_exp e = print_stm (EXP e)
@

<<function Tree.print_stm>>=
let print_stm =
  let rec iprintf = function
      0 -> Printf.printf
    | i -> (print_string "  "; iprintf (i-1))
  in
  let rec prstm d = function
    | LABEL l      -> iprintf d "LABEL:%s\n " (S.name l)
    | CONT(l,ls)   -> iprintf d "CONT:%s\n "  (S.name l)
    | TRY l        -> iprintf d "TRY:%s\n"    (S.name l)
    | TRYEND l     -> iprintf d "TRYEND:%s\n" (S.name l)
    | SEQ(a,b)     -> iprintf d "SEQ:\n";     prstm(d+1) a; prstm(d+1) b
    | MOVE(a,b)    -> iprintf d "MOVE:\n";    prexp(d+1) a; prexp(d+1) b
    | JUMP e       -> iprintf d "JUMP:\n";    prexp(d+1) e
    | EXP e        -> iprintf d "EXP:\n";     prexp(d+1) e
    | RET e        -> iprintf d "RET:\n";     prexp(d+1) e
    | CJUMP(a,t,f) -> iprintf d "CJUMP:\n";   prexp(d+1) a;
                      iprintf (d+1) "true  label: %s\n" (S.name t);
                      iprintf (d+1) "false label: %s\n" (S.name f)
  and prexp d = function
      BINOP(p,a,b)     -> iprintf d "BINOP:%s\n" (cmm_binop p);
                          prexp (d+1) a; prexp (d+1) b
    | RELOP(p,a,b)     -> iprintf d "RELOP:%s\n" (cmm_relop p);
                          prexp (d+1) a; prexp (d+1) b
    | MEM(e,_)         -> iprintf d "MEM:\n"; prexp (d+1) e
    | TEMP(t,_)        -> iprintf d "TEMP %s\n" (S.name t)
    | ESEQ(s,e)        -> iprintf d "ESEQ:\n";
                          prstm (d+1) s; prexp (d+1) e
    | NAME lab         -> iprintf d "NAME %s\n" (S.name lab)
    | CONST i          -> iprintf d "CONST %d\n" i
    | CALL(e,el,_,_,_) -> iprintf d "CALL:\n";
                          prexp (d+1) e; List.iter (prexp (d+2)) el
  in prstm 0
@

\section{[[tiger -dump_lext]]}

<<command line flags>>=
let dump_lext   = ref false
@
<<command line options>>=
"-dump_lext",     Arg.Set dump_lext,   "\tprint Linearized Expression Trees";
@

<<[[Main.emit_function()]] if dump linearized tree>>=
if !Option.dump_lext 
then List.iter Tree.print_stm ltree;
@



\chapter{Extra Code}

\ifallcode
#include "Tiger_extra.nw"
\fi

\chapter{Changelog}
\label{sec:changelog}

\chapter{Glossary}
\label{sec:glossary}

\begin{verbatim}
\end{verbatim}

\chapter*{Indexes}
\addcontentsline{toc}{section}{Index}

%\chapter{References} 
\addcontentsline{toc}{section}{References}

\begin{thebibliography}{99}

\bibitem[1]{wp-literate-programming} Donald Knuth,,
{\em Literate Programming}, 
\url{http://en.wikipedia.org/wiki/Literate\_Program}

\bibitem[2]{noweb} Norman Ramsey,
{\em Noweb}, 
\url{http://www.cs.tufts.edu/~nr/noweb/}

\bibitem[3]{syncweb} Yoann Padioleau,
{\em Syncweb, literate programming meets unison}, 
\url{http://padator.org/software/project-syncweb/readme.txt}

\end{thebibliography}

%******************************************************************************
% Postlude
%******************************************************************************

\end{document}

